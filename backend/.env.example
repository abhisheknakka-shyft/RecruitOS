# Which provider to use: openai | openrouter | gemini
LLM_PROVIDER=openrouter

# --- OpenRouter (OpenRouter.ai - many models including free Llama) ---
OPENROUTER_API_KEY=your-openrouter-api-key
MODEL_NAME=meta-llama/llama-3.1-8b-instruct:free

# --- OpenAI ---
# OPENAI_API_KEY=sk-your-key-here
# Optional; defaults to gpt-4o-mini
# OPENAI_MODEL=gpt-4o-mini

# --- Google Gemini ---
# GEMINI_API_KEY=your-gemini-key
# Optional; defaults to gemini-1.5-flash
# GEMINI_MODEL=gemini-2.5-flash

# --- Runtime / deployment ---
# Comma-separated frontend origins allowed to call the API.
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Comma-separated hostnames this API will accept in Host header.
TRUSTED_HOSTS=localhost,127.0.0.1

# Optional: override backend data directory (default: backend/data).
# RECRUITOS_DATA_DIR=/app/backend/data

# Optional: runtime port/worker count if your process launcher uses them.
PORT=8000
UVICORN_WORKERS=1
